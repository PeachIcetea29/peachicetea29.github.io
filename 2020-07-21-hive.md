HIVE
==================
![](https://t1.daumcdn.net/cfile/tistory/9996413B5A2FEF5B02)
* 하둡 기반의 데이터 웨어하우징 프레임워크
* 사용자의 워크스테이션에서 실행되고, 작성된 SQL Query는 일련의 MR Job으로 변환되어 하둡 클러스터에서 구동된다.
* HDFS에 저장된 데이터(디렉터리, 파일)에 구조(스키마)를 입히는 방식으로 데이터를 테이블로 구조화시킨다.
* 테이블 스키마와 같은 메타데이터는 `metastore`라 불리는 데이터베이스에 저장된다.

## 설치

1. HIVE 다운로드 
```
wget http://mirror.apache-kr.org/hive/hive-2.3.6/apache-hive-2.3.6-bin.tar.gz
sudo tar -zxvf ./apache-hive-2.3.6-bin.tar.gz -C /usr/local/
```

2. 소유자를 root가 아닌 hadoop 운영 계정으로 변경

```
sudo chown -R user:hadoop /usr/local/apache-hive-2.3.6-bin/
```

3. .bashrc에 환경설정 추가
```
vi ~/.bashrc
export HIVE_HOME=/usr/local/apache-hive-2.3.6-bin/
export PATH=$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH
```

4. HIVE 설정 파일 수정
    * hive-env.sh
        > Hadoop 파일이 있는 경로로 수정
        ```
        HADOOP_HOME=/usr/local/hadoop
        ```
    * hive-site.xml
        > 클러스터 연결을 위한 세부사항을 정의한 파일
        ```
        <configuration> 
            <property> 
                <name>javax.jdo.option.ConnectionURL</name> 
                <value>jdbc:mysql://localhost:3306/metastore?createDatabaseIfNotExist=true</value> 
            </property> 
            <property> 
                <name>javax.jdo.option.ConnectionDriverName</name> 
                <value>org.mysql.jdbc.Driver</value> 
            </property> 
            <property> 
                <name>javax.jdo.option.ConnectionUserName</name> 
                <value>hive</value> 
            </property> 
            <property> 
                <name>javax.jdo.option.ConnectionPassword</name> 
                <value>[password]</value> 
            </property> 
        </configuration>
        ```

5. MYSQL 내 metastore 데이터베이스 생성
```
mysql> CREATE DATABASE metastore DEFAULT CHARACTER SET utf8;
mysql> CREATE USER 'hive'@'%' IDENTIFIED BY '[password]';
mysql> GRANT ALL PRIVILEGES ON metastore.* TO 'hive'@'%';
mysql> FLUSH PRIVILEGES;
```

6. MySQL JDBC Connector 설치

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbbVhFB%2FbtqCAP3E74J%2Fnz2SnEWNKcNf6mjKDg6ov0%2Fimg.png)

* 위 표를 참고하여 버전에 맞는 JDBC connector 설치
```
ex) jdk 8.0의 경우 jdbc connector 5.1 설치
wget https://downloads.mysql.com/archives/get/p/3/file/mysql-connector-java-5.1.47.tar.gz
```
이후 압축해제 하여 ~bin.jar 파일을 HIVE 라이브러리 폴더로 이동
```
tar -zxvf ./mysql-connector-java-5.1.47.tar.gz
mv mysql-connector-java-5.1.47-bin.jar /usr/local/apache-hive-2.3.6-bin/lib
```

7. HDFS 디렉토리 생성
> 하둡 클러스터 하나를 여러 명의 사용자가 공유해야 할 때, 모든 사용자가 파일을 쓸 수 있는 디렉토리를 만들어주는 것.
```
> hadoop dfs -mkdir /tmp
> hadoop dfs -mkdir -p /user/hive/warehouse
> hadoop dfs -chmod a+w /tmp
> hadoop dfs -chmod -R a+w /user

* 사용자가 같은 그룹이면 g+w 권한으로도 충분
```

8. Metastore 초기화
```
schematool -dbType mysql -initSchema
```
위의 명령어를 이용해 메타 정보를 초기화

## 하이브 쉘

* HiveQL 명령어로 하이브와 상호작용하는 기본 도구. SQL과 유사한 Query 언어이다.
* -f 옵션을 이용하면 파일을 이용해서 비대화식모드로 실행할 수 있다.
    ```
    > hive -f script.q
    ```
* -e 옵션을 이용하면 직접 입력할 수 있고, 세미콜론을 붙이지 않아도 된다.
    ```
    > hive -e 'SELECT * FROM dummy'
    ```
---------------------------------------------------

## 예제
```
CREATE TABLE records(year STRING, remperature INT, quality INT)
ROW FORMAT DELIMTED
FIELDS TERMINATED BY '\t';

>> 각 컬럼으로 구성된 records 테이블을 선언
>> 탭으로 분리된 텍스트임을 의미해 탭과 개행 문자로 필드와 행을 각각 구분, 각 컬럼에 해당하는 값이 들어가게 함
```

```
HDFS에서 로딩
LOAD DATA INPATH 'input/~/sample.txt' OVERWRITE INTO TABLE records;

로컬에서 로딩
LOAD DATA LOCAL INPATH 'input/~/sample.txt' OVERWRITE INTO TABLE records;
>> 하이브의 웨어하우스 디렉토리에 로드(메타스토어에 삽입)
>> 웨어하우스 디렉토리는 hive.metastore.warehouse.dir 속성으로 설정 (기본값은 '/user/hive/warehouse')
```

---------------------------------------------------

* SET 명령어를 이용해 환경 설정을 변경할 수 있다.
    ```
    hive> SET hive.enforce.bucketing=true;
    ```
* 현재 값을 보고싶다면 SET 다음에 속성이름을 입력
    ```
    hive> SET hive.enforce.bucketing;
    hive.enforce.bucketing=true
    ```
* 속성 설정에 대한 우선순위는 아래와 같은 순서
    1) hive SET 명령어
    2) 명령행의 -hiveconf 옵션
    3) hive-site.xml, 하둡 site 파일들(core-site.xml, hdfs-site.xml, mapred-site.xml, yarn-site.xml)
    4) 하이브 기본 파일과 하둡 기본 파일(core-defalut.xml, hdfs-default.xml, mapred-default.xml, yarn-default.xml)
       
## 실행 엔진

* 실행 엔진으로 맵리듀스 사용하도록 작성되었기에 기본 엔진은 맵리듀스.

* 실행 엔진으로 아파치 테즈를 사용해서 하이브를 싱핼할 수 있으며, 스파크도 현재 지원
    * 테즈와 스파크의 경우 맵리듀스보다 더 높은 성능과 유연성을 제공하는 Directed acyclic graph(DAG) 엔진
    * Job의 임시 출력을 HDFS에 저장하는 맵리듀스와 달리, 테즈와 스파크는 로컬 디스크에 기록하거나 메모리에 저장하는 방식
* hive.execution.engine 속성으로 관리(기본값은 맵리듀스)ㄴ
    ```
    hive> SET hive.execution.engine=tez;
    ```
## 로깅
* 에러 로그는 로컬 파일시스템의 /tmp/${user.name}/hive.log에서 찾을 수 있다.
* -conf 옵션을 사용하여 다른 디렉토리로 설정 가능
    ```
    > hive -hiveconf hive.log.dir='/tmp/user'
    ```

## 메타스토어
![](https://i.stack.imgur.com/vZjQY.png)
* 메타데이터의 핵심 저장소로, 서비스와 데이터 보관 저장소로 나뉜다.
* 기본적으로 메타데이터 서비스는 하이브 서비스와 동일한 JVM에서 실행되고, 로컬 디스크에 저장되는 내장형 더비 데이터베이스 인스턴스를 포함한다.
* Embedded metastore
    * 하이브를 가장 쉽게 사용할 수 있는 방식
    * 한번에 데이터베이스 파일 하나에만 접근할 수 있어, 사용자가 동일한 메타스토어를 공유하는 경우 단 하나의 하이브 세션만 사용할 수 있다.
* Local metastore
    * 다중 세션을 지원하는 방법으로, 독립형 데이터 베이스를 사용하는 방식
    * 메타스토어 서비스는 하이브 서비스와 동일한 프로세스에서 실행되지만, 별도의 프로세스로 실행되는 데이터베이스와 연결할 수 있다
* Remote metastore
    * 하나 이상의 메타스토어 서버가 하이브 서비스와 별도의 프로세스로 실행된다.
    * 원격 메타스토어를 설정해두면, 데이터베이스 계층이 방화벽의 역할을 대신하여 관리성과 보안성이 더 높다
    * hive.metastore.uris 설정을 이용하여 원격 메타스토어를 설정할 수 있다(다수의 메타스토어 서버를 설정할때는 URI를 콤마로 구분하여 입력)

## 전통적인 데이터베이스와 비교
* 하이브는 데이터를 로드하는 시점이 아닌 쿼리를 실행할 때 데이터를 검증하는 `Schema on read`방식
* 데이터베이스 내부 형식으로 데이터를 읽거나 또는 파싱할 때, 디스크에 직렬화할 필요가 없어 매우 빠르게 데이터를 로드할 수 있다. 즉, 데이터를 로드할 때 단순 파일을 복사하거나 이동하기만 하면 된다.
    * 데이터를 로드하는 시점에 테이블의 스키마가 검증되는 Schema on write의 경우, 데이터베이스에 데이터를 로드하는 시간은 더 오래 걸리는 대신 query를 더 빠르게 수행할 수 있다. 또한 query가 정해지지 않은 로드시점엔 당연히 스키마를 지정할 수 없고 index도 적용할 수 없는 경우도 빈번하기에, 하이브가 이 상황에서는 적절하다고 볼 수 있다

* 갱신, 트랜잭션, 색인
    * 하이브는 맵리듀스를 사용하는 HDFS에 저장된 대용량 데이터를 다루기 때문에, 전체 테이블을 스캔하는 방식으로만 구현되어있다.
    * 갱신 또한 아예 새로운 테이블을 만들어 데이터를 변환하는 방식으로 구현한다.
    * HDFS는 이처럼 기존 파일의 갱신을 지원하지 않기 때문에 삽입, 변경, 삭제로 인한 갱신 내역은 별도의 작은 파일에 저장된다. 이러한 델타 파일은 메타스토어에서 백그라운드로 실행되는 MR Job에 의해 기존 테이블과 주기적으로 병합된다.
    * 테이블과 파티션 수준의 잠금을 짖원하여, 특정 프로세스가 테이블을 읽는 도중 다른 프로세스가 해당 테이블을 처리하는 것을 방지할 수 있다.
    * compact index와 bitmap index를 지원한다.
        * compact index의 경우 값을 파일 오프셋이 아닌 HDFS 블록 넘버로 저장해 인접한 행 사이에 분포된 특정 컬럼에 대한 값을 찾는데 효과적이다.
        * bitmap index는 특정 값이 출현하는 행을 효율적으로 저장하기 위해 압축된 bitset을 이용하는 방식이다.

## HIVE QL
![](https://lh3.googleusercontent.com/WCAwYdZvc8dOXQa1QUvnEBJaa0TVISacct-RsOFc2778w6fnbqO6UF7dXgWPKN6HxIO_LocDyJbrSt4n0cy-FagtV92T4O7A9TISyTrbWkG7R0QKWIzswhvpdmWz5jhsQWIBC56tloW0hz1pZQ)