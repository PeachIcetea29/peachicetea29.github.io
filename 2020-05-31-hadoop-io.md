Hadoop I/O
==================

* Checksum을 이용해 손상된 데이터 검출
* HDFS에서는 CRC-32C라고 불리는 변형 체크섬을 사용한다

## HDFS의 데이터 무결성

* HDFS는 모든 데이터를 쓰는 과정에서 내부적으로 체크섬을 계산, 읽는 과정에서 검증한다.
* 데이터노드는 데이터와 체크섬을 저장하기 전에 수신한 데이터를 검증
* 파이프라인의 마지막 데이터노드가 해당 데이터의 체크섬을 검증
* 클라이언트가 데이터노드로부터 데이터를 읽을 때 클라이언트 역시 데이터노드에 저장된 체크섬과 수신된 데이터로부터 체크섬을 검증
* 체크섬에 대한 로그를 저장해서 오류 검출에 유용
* 각 데이터노드는 저장된 모든 블록을 주기적으로 검증하는 DataBlockScanner를 백그라운드 스레드로 수행. 물리 저장 매체에서 발생할 수도 있는 비트 로트<sup>bit rot</sup>에 대한 데이터 손실을 피함
 * 체크섬을 이용해 손상된 복제본 복구

 ## LocalFileSystem

* 클라이언트 측 체크섬을 수행
* 기존 파일시스템이 자체적으로 체크섬을 지원한다면 사용하지 않아도 괜찮음
* ChecksumFileSystem을 활용한다.

## 압축
* 파일 용량을 줄이고, 네트워크 또는 디스크로부터 전송 속도를 높일 수 있음
* 모든 압축 알고리즘은 압축과 해제가 빨라질수록 공간이 늘어나는 희생을 감수해야 하기 때문에 공간과 시간은 트레이드오프 관계에 있다.
* 맵리듀스에는 분할 가능한 압축 포맷이 적합하다

## 코덱

* 압축-해제 알고리즘을 구현한 것
* CompressionCodec을 이용해 대이터를 압축하거나 해제
    * 출력 스트림에 쓸 데이터를 압축할때는 createOutputStream 메서드
    * 입력 스트림으로부터 읽어 들인 데이터를 압축 해제하려면 createInputStream 메서드
    * CompressionCodecFactory를 사용하여 어떤 codec인지 유추 가능

* 성능 관점에서는 압축과 해제를 위해 원시 라이브러리를 사용하는 것이 바람직
    * 원시 gzip 라이브러리를 사용했을 때, 압축 해제 성능은 최대 50%, 압축 성능은 거의 10%정도 더 좋아짐(내장된 자바 구현과 비교)
* 기본적으로 하둡은 자신이 수행되는 플랫폼에 맞는 원시 라이브러리를 먼저 찾고, 있으면 자동으로 해당 라이브러리를 로드한다
* 원시 라이브러리를 사용하고 application에서 상당히 많은 압축 또는 해제 작업을 수행해야 한다면, CodecPool을 사용하는 것이 좋다

```
                                        어떤 압축 포맷을 사용하는게 좋을까?

1) 압축과 분할 모두 지원하는 시퀀스 파일, 에이브로, ORCFile, 파케이 같은 컨테이너 파일 포맷
2) bzip2 같이 분할 지원하는 압축 포맷. 분할을 지원하기 위해 색인될 수 있는 LZO같은 포맷
3) 애플리케이션에서 파일을 청크로 분할하고, 지원되는 모든 압축 포맷을 사용해 각 청크를 개별적으로 압축(압축된 청크 크기가 하나의 HDFS 블록 만큼의 크기가 되도록)
4) 파일을 압축하지 말고 그냥 저장
```

## 직렬화

* 네트워크 전송을 위해 구조화된 객체를 바이트 스트림으로 전환하는 과정
* 하둡 시스템에서 RPC를 이용해 노드 사이의 프로세스간 통신이 이루어지는데, 이 때 메시지를 하나의 바이너리 스트림으로 구성하기 위해 직렬화를 사용
* RPC뿐만아니라 영속적 데이터 저장에도 좋음
* 장점
    * 간결성
        * 네트워크 대역폭 절약
    * 고속화
        * 오버헤드를 줄여 backbone 형성에 용이
    * 확장성
        * 새로운 요구사항을 만족시키기 위한 프로토콜의 발전에 용이
    * 상호운용성
        * 다양한 언어로 작성된 클라이언트 지원 가능

## Writable
* 하둡에서는 Writable이라는 직렬화 포맷 사용
* org.apache.hadoop.io 패키지에서 여러 Writable 클래스 제공


## 자바 기본 자료형 Writable wrapper
* char를 제외한 모든 자바 기본 자료형을 위한 writable wrapper 존재
* get과 set메서드를 이용해 값 이용

|자바 기본 자료형 | Writable 구현체 | 직렬화된 크기(바이트)|
|--------------  |----------------|------|
|boolean|BooleanWritable|1|
|byte|ByteWritable|1|
|short|ShortWritable|2|
|int|IntWritable(고정길이)|4|
|   |VIntWritable(가변길이)|1~5|
|float|FloatWritable|4|
|long|LongWritable(고정길이)|8|
|   |VLongWritable(가변길이)|1~9|
|double|DoubleWritable|8|

* 숫자값은 대부분 균일하지 않게 분포되어 가변길이 인코딩을 선택하는 것이 저장 공간 절약면에서 좋음

## Text
* UTF-8 시퀀스
* 가변길이 인코딩으로 int를 사용
* Text 클래스에서 인덱스는 인코딩된 바이트 시퀀스의 위치 관점(string처럼 자바 char 코드 단위 위치 관점이 아님)
* Text에서 유니코드 문자를 반복할 때는 인덱스를 위해 바이트 오프셋을 사용해야 하므로 복잡한 편
* String과의 다른 차이점은 가변적이라는 것
* tostring()을 이용해 string으로 변환 가능

## BytesWritable
* 바이너리 데이터의 배열에 대한 wrapper
* 데이터의 바이트 길이를 지정하는 4바이트 정수 필드에 해당 데이터가 뒤따르는 구조
    * ex) 3과 5 값을 가지는 길이가 2인 바이트 배열 => 4바이트 정수(00000002) + 2바이트(03) + 2바이트(05) = 000000020305
* 가변적이고 set()을 이용해 변경 가능

## NullWritable
* 길이가 0인 특별한 직렬화. 어떠한 바이트도 읽거나 쓸 수 없다
* placeholder로 사용
* singleton이기에, get()으로 호출하여 얻어야 한다.

## ObjectWritable & GenericWritable
* ObjectWritable은 자바 기본 자료형 및 자료형 배열을 위한 범용 wrapper
* RPC에서 메서드 parameter와 return type을 위해 사용
* 범용 메커니즘을 직렬화할 때마다 쓰는 것은 공간 낭비가 생길 수 있기 때문에, 자료형의 수가 적고 미리 알려진 경우에는 정적 자료형 배열과 그 자료형에 대한 직렬화된 배열의 인덱스를 사용하는 GenericWritable로 공간 낭비를 줄일 수 있다.

## Writable collection
* collection type 지원
    * Array, ArrayPrimitve, TwoDArray, Map, SortedMap, EnumSet 등 

## Custom Writable
* 하둡이 기본으로 제공하는 Wirtable으로 대부분 적절하게 사용할 수 있지만, 모든 데이터를 string으로 바꾼다던지, single key 혹은 single value만 필요하다던지 등 커스텀 writable을 구현해야 할 때도 있다.
```{.java}
 class point3D {
    public float x;
    public float y;
    public float z;
}
//위와 같은 class를 전송해야할 때, string으로 변환하기에 매우 복잡
//맵리듀스 과정에서 하둡은 sorting과 shuffling을 하기때문에 string으로 이상하게 정렬될 가능성이 있음
```
* readField와 Write를 이용해 serialization과 deserialization를 위임
* hashcode(), equals(), tostring() 반드시 재정의 필요
```{.java}
import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;
 
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.WritableComparable;
 
public class TextPair implements WritableComparable {
 
    private Text first;
    private Text second;
 
    public TextPair(Text first, Text second) {
        set(first, second);
    }
 
    public TextPair() {
        set(new Text(), new Text());
    }
 
    public TextPair(String first, String second) {
        set(new Text(first), new Text(second));
    }
 
    public Text getFirst() {
        return first;
    }
 
    public Text getSecond() {
        return second;
    }
 
    public void set(Text first, Text second) {
        this.first = first;
        this.second = second;
    }
 
    @Override
    public void readFields(DataInput in) throws IOException {
        first.readFields(in);
        second.readFields(in);
    }
 
    @Override
    public void write(DataOutput out) throws IOException {
        first.write(out);
        second.write(out);
    }
 
    @Override
    public String toString() {
        return first + " " + second;
    }
 
    @Override
    public int compareTo(TextPair tp) {
        int cmp = first.compareTo(tp.first);
 
        if (cmp != 0) {
            return cmp;
        }
 
        return second.compareTo(tp.second);
    }
 
    @Override
    public int hashCode(){
        return first.hashCode()*163 + second.hashCode();
    }
 
    @Override
    public boolean equals(Object o)
    {
        if(o instanceof TextPair)
        {
            TextPair tp = (TextPair) o;
            return first.equals(tp.first) && second.equals(tp.second);
        }
        return false;
    }
 
}
```

* RawComparator
    * 최적화 방법
    * 위의 예제에서 textpair가 맵리듀스의 키로 사용될려면 deserialization 과정이 필요한데, 이 과정을 거치지않고 바이너리 상태에서 바로 비교하는 것
    * 바이너리 스트림에서 첫 번째 text 객체가 바이트의 개수를 포함한 가변길이 정수이기 때문에, 오프셋을 이용해 바로 접근하는것
    * 이를 이용해 custom comparator 구현 가능

Serialization Framework
-----------------------
* 꼭 Writable key와 value 타입을 사용해야 하는것은 아님
* 모든 타입이 사용될 수 있으며, 각 타입에 대한 바이너리 표현의 변환 메커니즘으로 하둡에서 `Serialization Framework API` 제공
    * ex) Writable 타입을 위한 WritableSerialziation
    * Serializer instance & Deserializer instance
* java의 객체 직렬화를 사용하지 않는 이유는 무거워서?
    * 간결성, 고속화, 확장성, 상호운용성등 serialization 포맷에 대한 표준을 만족시키지 않아서

* serialization IDL
    * `Interface Description Language`를 사용하여 언어 중립적이고 선언적 방식으로 인터페이스를 표현
        * 주로 RPC를 이용한 소프트웨어에서 많이 사용되는 방식
    * 다양한 언어로 타입을 생성할 수 있기 때문에 `상호운용성`이 매우 좋다.
        * 같은 언어를 사용하지 않는 소프트웨어 컴포넌트 사이의 통신을 가능하게 함
    * 대표적으로 `아파치 쓰리프트`, `구글 프로토콜 버퍼` 등이 있다
    * 하둡에 저장된 대규모 데이터 처리에 적합한 IDL기반의 프레임워크인 `에이브로`

SequenceFile
---------------------
![](https://i.stack.imgur.com/TAi9n.png)
* 바이너리 형태로 로그를 남기고 싶을 때, 바이너리 key-value에 대한 영속적인 데이터 구조를 제공하는 SequenceFile 활용
* 작은 파일 여럿을 하나의 큰 파일로 합치는 개념
* HDFS와 맵리듀스는 일반적으로 큰 파일에 최적화 되있기에, SequenceFile을 이용하여 작은 파일을 위한 컨테이너로도 활용할 수 있다

* 장점
    * Namenode에 필요한 메모리를 절약할 수 있음
    * 쪼갤수 있기 때문에, mapReducedp 적합
    * 압축 지원

* 생성하는 법
    * SequenceFile.Writer 인스턴스 활용
    * append 메서드를 이용해 key-value 쌍을 입력

* 읽기
    * SequenceFile.Reader 인스턴스 활용
    * next() 메서드를 이용해 레코드 하나씩 읽는 방식
    * Writable 타입이라면 next로 key와 value한 쌍을, 직렬화 프레임워크라면 next와 getCurrentVlaue 두가지 메서드를 이용

* sync point
    * 리더가 해당 스트림에서 임의의 위치를 탐색한 후 자신의 위치를 잃어버렸을 때, 레코드의 경계를 재동기화하는데 사용될 수 있는 스트림의 지점
    * sequenceFile이 만들어질 때, 특별한 개체를 추가하여 기록
    * 레코드의 경계에 맞춰짐

* 정렬 & 병합
    * 하나 이상의 sequenceFile을 정렬하고 병합할 때는 맵리듀스가 가장 유용
        * 병렬성이 타고난 맵리듀스
        * 리듀서의 수로 출력 파티션 수 조정 가능

* 포맷
```
* 단일 헤더와 하나 이상의 레코드로 구성
* 헤더에는 key와 value 클래스의 이름, 압축 세부사항, 사용자 정의 메타데이터, sync point가 포함된 여러 필드로 구성되어있다
```
* Default(비압축)
    * ![](https://i.stack.imgur.com/vy5SU.png)
    * 레코드는 레코드 길이(바이트 단위), 키 길이, key와 value로 구성
    * 길이 필드는 4byte
    * key와 value는 sequenceFile을 위한 serialization으로 직렬화 되어있음
* 레코드 압축 
    * 비압축 방식과 거의 유사하며, 헤더에 정의된 코덱을 사용해 value의 바이트를 압축
* 블록 압축
    * ![](https://i.stack.imgur.com/LmiHb.png)
    * 다수의 레코드를 한번에 압축한 방식
    * 레코드 압축보다 블록 압축이 밀도가 더 높고, 레코드간 유사성을 이용할 수 있기 때문에 일반적으로 레코드 압축보다 더 선호
    * 레코드를 정의된 블록 최소 크기에 이를 때까지 바이트단위로 블록에 추가
    * sync point는 각 블록의 앞에 위치

MapFile
----------------------------
* key를 기준으로 검색을 지원하는 index를 포함한 정렬된 sequenceFile
    * index file은 data file에 대해 key(위치)와 value(오프셋)로 구성
* 빠른 검색을 위해 지원
    * 전체 레코드를 검색하는 것이 아닌 index를 이용한 스캔
    * index로만 이루어져있어 용량이 적기 때문에 메모리에 올려 사용
* 하둡에서는 변형 MapFile 제공
    * SetFile
        * Writable key의 집합을 저장하는 MapFile.
        * Key는 정렬된 순으로 추가
    * ArrayFile
        * key는 배열의 index를 표현하는 정수, value는 Writable 값으로 이루어진 MapFile
    * BloomMapFile
        * 빠른 get() 메서드를 지원
        * 데이터가 드문드문 분포된 파일에 적합하다
        * 검증 작업이 메모리에서 처리되므로 빠르긴 하지만 false positive 가능성이 있음(실제로 거짓이지만, 결과가 참으로 나오는 경우)
* 에이브로 데이터 파일 권장

* ![](https://i1.wp.com/timepasstechies.com/wp-content/uploads/2017/07/column-row.jpg?fit=1433%2C1404)
    * Row based
        * sequenceFile, MapFile, 에이브로 모두 row 기반 포맷
        * 각 row의 값이 파일에서 연속된 위치에 저장되어 있음을 의미
        * write 실패하더라도 마지막 sync point까지 읽을 수 있음
    * Column based
        * 각 파일이 먼저 row 기준의 여러 조각으로 분리되고, 각 조각이 column 기준으로 저장됨
        * column 기반 구조는 접근할 필요가 없는 column은 건너뛸 수 있는 것이 이점
        * 파일의 오직 두 부분만 메모리에 로드되므로, 일반적으로 테이블에서 소수의 column만 접근할 때 잘 작동한다(단일 row에서 많은 column을 접근할 때는 row based가 더 적합)
        * read, write할 때 더 많은 메모리가 필요
            * 하나의 row를 읽고 쓰는 것이 아닌, 메모리에 있는 데이터를 각 row로 분리하는 버퍼가 추가로 필요하기 때문
            * flush, sync 조작 제어 불가능
            * write 실패시, 파일을 복구할 수 없어 스트리밍 쓰기에는 부적합
        * 하이브의 RCFile이 대표적 => ORCFile과 파케이<sup>Parquet</sup>로 대체